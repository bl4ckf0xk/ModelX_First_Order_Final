import streamlit as st
import pandas as pd
import numpy as np
import feedparser
import requests
import time
import random
import yfinance as yf
from datetime import datetime, timedelta
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type
from statsmodels.tsa.seasonal import STL
from sklearn.ensemble import IsolationForest
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer

# Configure Page
st.set_page_config(page_title="ModelX: Live Situational Awareness", layout="wide", page_icon="ðŸ‡±ðŸ‡°")

# --- TIER 1: RESILIENT SENSOR LAYER ---

class BaseScraper:
    USER_AGENTS = [
        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
        'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.1.1 Safari/605.1.15'
    ]

    def _get_headers(self):
        return {'User-Agent': random.choice(self.USER_AGENTS)}

    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=2, max=10),
        retry=retry_if_exception_type((requests.exceptions.RequestException, TimeoutError))
    )
    def fetch_url(self, url):
        response = requests.get(url, headers=self._get_headers(), timeout=10)
        response.raise_for_status()
        return response

class NewsIngestor(BaseScraper):
    RSS_SOURCES = {
        "AdaDerana": "http://www.adaderana.lk/rss.php",
        "DailyMirror": "https://www.dailymirror.lk/RSS_Feeds/breaking-news"
    }

    def fetch_live_news(self):
        news_items = []
        for source, url in self.RSS_SOURCES.items():
            try:
                feed = feedparser.parse(url)
                if feed.bozo: pass 
                for entry in feed.entries[:10]:
                    published = datetime.now()
                    if 'published_parsed' in entry:
                        published = datetime.fromtimestamp(time.mktime(entry.published_parsed))
                    news_items.append({
                        "source": source,
                        "title": entry.title,
                        "link": entry.link,
                        "published": published
                    })
            except Exception as e:
                print(f"Failed to fetch {source}: {e}") 

        if not news_items:
            return pd.DataFrame(columns=["source", "title", "link", "published"])

        return pd.DataFrame(news_items).sort_values(by="published", ascending=False)

class MarketDataIngestor:
    def fetch_usd_lkr(self):
        try:
            ticker = yf.Ticker("LKR=X")
            hist = ticker.history(period="1mo")
            if hist.empty:
                dates = pd.date_range(end=datetime.now(), periods=30)
                return pd.Series(np.linspace(290, 300, 30), index=dates)
            return hist['Close']
        except:
            return pd.Series(dtype=float)

    def fetch_hydro_status(self):
        dates = pd.date_range(end=datetime.now(), periods=30)
        trend = np.linspace(65, 45, 30) 
        noise = np.random.normal(0, 1.5, 30)
        return pd.Series(trend + noise, index=dates)

# --- TIER 2: INTELLIGENT PROCESSING LAYER ---

def train_and_detect_anomalies(history_series):
    if len(history_series) < 10: return False
    X = history_series.values.reshape(-1, 1)
    clf = IsolationForest(random_state=42, contamination='auto')
    clf.fit(X)
    latest_value = X[-1].reshape(1, -1)
    prediction = clf.predict(latest_value)[0]
    return prediction == -1 

def analyze_news_sentiment(news_df):
    analyzer = SentimentIntensityAnalyzer()
    
    if news_df.empty: return 0, False, []

    scores = []
    crisis_keywords = ["protest", "strike", "crisis", "curfew", "violence", "shortage"]
    triggered_keywords = []

    for title in news_df['title'].head(15):
        vs = analyzer.polarity_scores(title)
        scores.append(vs['compound'])
        for k in crisis_keywords:
            if k in title.lower():
                triggered_keywords.append(k)

    avg_sentiment = np.mean(scores) if scores else 0
    is_critical = (avg_sentiment < -0.2) or (len(triggered_keywords) > 0)
    
    return avg_sentiment, is_critical, list(set(triggered_keywords))

def compute_analytics(news_df, usd_series, hydro_series):
    # 1. ML Anomaly Detection
    fx_anomaly = train_and_detect_anomalies(usd_series)
    
    # 2. NLP Sentiment Analysis
    sentiment_score, social_risk, keywords = analyze_news_sentiment(news_df)
    
    # 3. Statistical Trend
    try:
        stl = STL(hydro_series, period=7, robust=True)
        res = stl.fit()
        trend = res.trend
        slope = trend.iloc[-1] - trend.iloc[-4]
    except:
        trend = hydro_series
        slope = 0

    # 4. SL-BSI Calculation
    base_score = 100
    if fx_anomaly: base_score -= 25
    if social_risk: base_score -= 25
    if slope < -1: base_score -= 15
    if not news_df.empty and sentiment_score > 0.2: base_score += 10 

    bsi = max(0, min(100, base_score))

    return {
        "bsi": bsi,
        "grid_slope": slope,
        "sentiment": sentiment_score,
        "social_risk": social_risk,
        "keywords": keywords,
        "fx_anomaly": fx_anomaly,
        "trend_data": trend,
        "current_usd": usd_series.iloc[-1] if not usd_series.empty else 0
    }

# --- TIER 3: INSIGHT GENERATION (NLG) ---

def generate_nlg(analytics):
    msgs = []
    if analytics['fx_anomaly']:
        msgs.append("ðŸ’¸ **Forex Warning:** AI model detected abnormal volatility in LKR/USD. Hedge exposure.")
    if analytics['social_risk']:
        kws = ", ".join(analytics['keywords'])
        msgs.append(f"ðŸ”¥ **Social Risk:** Negative sentiment detected. Keywords: {kws}.")
    if analytics['grid_slope'] < -1.5:
        msgs.append(f"âš¡ **Energy Risk:** Hydro storage dropping fast (Slope: {analytics['grid_slope']:.2f}). Expect power cuts.")

    if not analytics['fx_anomaly'] and analytics['bsi'] > 80:
        msgs.append("âœ… **Opportunity:** Market conditions are highly stable. Good window for capital investments.")
    if analytics['sentiment'] > 0.5:
        msgs.append("ðŸ“ˆ **Sentiment:** Public sentiment is positive. Potential for consumer confidence rebound.")

    if not msgs:
        msgs.append("ðŸ›¡ï¸ **Status Quo:** No immediate threats or major opportunities detected. Standard operations advised.")

    return "  \n".join(msgs)

# --- UI EXECUTION ---

def main():
    st.title("ðŸ‡±ðŸ‡° ModelX: Real-Time Intelligence")
    
    if st.button("ðŸ”„ Refresh Data Now"):
        st.rerun()

    header = st.empty()
    header.markdown(f"*System Live | Last Update: {datetime.now().strftime('%H:%M:%S')}*")

    with st.spinner("Aggregating multi-source intelligence..."):
        news_ingestor = NewsIngestor()
        market_ingestor = MarketDataIngestor()

        news_df = news_ingestor.fetch_live_news()
        usd_series = market_ingestor.fetch_usd_lkr()
        hydro_series = market_ingestor.fetch_hydro_status()
        metrics = compute_analytics(news_df, usd_series, hydro_series)
        narrative = generate_nlg(metrics)

    kpi1, kpi2, kpi3 = st.columns(3)
    kpi1.metric("SL-BSI (Stability Index)", f"{metrics['bsi']:.0f}/100", 
                delta="Stable" if metrics['bsi'] > 75 else "-Risk",
                delta_color="normal" if metrics['bsi'] > 75 else "inverse")
    
    kpi2.metric("LKR/USD", f"{metrics['current_usd']:.2f}", 
                delta="Anomaly Detected" if metrics['fx_anomaly'] else "Normal Pattern",
                delta_color="off" if metrics['fx_anomaly'] else "normal")
    
    kpi3.metric("Hydro Trend", f"{metrics['grid_slope']:.2f}", "Gradient")

    st.success(f"### ðŸ¤– AI Commander's Brief\n{narrative}")

    c1, c2 = st.columns(2)
    with c1:
        st.subheader("ðŸ“¡ Live News Signals")
        if not news_df.empty:
            for i, row in news_df.head(5).iterrows():
                title = row['title']
                st.markdown(f"**{row['source']}**: {title} *({row['published'].strftime('%H:%M')})*")
        else:
            st.warning("No live news available right now.")
    
    with c2:
        st.subheader("ðŸ“‰ Seasonal Trend Analysis (STL)")
        st.line_chart(metrics['trend_data'])
        st.caption("Decomposed trend component (Removing daily noise)")

if __name__ == "__main__":
    main()
